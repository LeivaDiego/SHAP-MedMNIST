{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7b98ac",
   "metadata": {},
   "source": [
    "# Laboratorio 3: SHAP MedMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e90ab",
   "metadata": {},
   "source": [
    "## ========= 1) Setup ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install required libraries if needed\n",
    "# !pip install medmnist torch torchvision shap matplotlib\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dcf81",
   "metadata": {},
   "source": [
    "## ========= 2) Dataset Info ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1965412fe82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pathmnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "n_classes = len(info['label'])\n",
    "id2label = {int(k): v for k, v in info['label'].items()}\n",
    "\n",
    "print(f\"Dataset: {info['description']}\")\n",
    "print(f\"Task: {info['task']}, Classes: {n_classes}\")\n",
    "print(\"Classes:\", id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b643830c",
   "metadata": {},
   "source": [
    "## ========= 3) Load dataset ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d33628073a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "])\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=transform, download=download)\n",
    "test_dataset  = DataClass(split='test', transform=transform, download=download)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset), \" Test size:\", len(test_dataset))\n",
    "\n",
    "# Show 5 sample images\n",
    "fig, axs = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    img, label = train_dataset[i]\n",
    "\n",
    "    # Ensure img is a numpy array\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        lbl = label.item()\n",
    "    elif isinstance(label, np.ndarray):\n",
    "        lbl = label.item()\n",
    "    else:\n",
    "        lbl = label\n",
    "\n",
    "    img = img.numpy().transpose(1, 2, 0).squeeze()\n",
    "    axs[i].imshow(img, cmap=\"gray\")\n",
    "    axs[i].set_title(f\"{id2label[int(lbl)]}\")  # ✅ cast label to int\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763666b",
   "metadata": {},
   "source": [
    "## ========= 4) Define Simple CNN Model (already provided) ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdca4bb7e963e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16*14*14, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(info['n_channels'], n_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model class defined and ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339b8e0",
   "metadata": {},
   "source": [
    "## ========= 5) Load Pretrained Model ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719121bf5fd15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"pathmnist_simplecnn.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Pretrained model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4551de1",
   "metadata": {},
   "source": [
    "## ========= 6) Predictions + SHAP Explanations ========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166186e",
   "metadata": {},
   "source": [
    "**In this cell, you will:**\n",
    "1. Write a helper function so SHAP can call the model\n",
    "2. Pick one test image and predict its class\n",
    "3. Compare prediction vs. true label\n",
    "4. Use SHAP to explain WHY the model made that prediction\n",
    "5. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ff879",
   "metadata": {},
   "source": [
    "## ========= 6) Predictions + SHAP Explanations ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74816226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, you will:\n",
    "#   1. Write a helper function so SHAP can call the model\n",
    "#   2. Pick one test image and predict its class\n",
    "#   3. Compare prediction vs. true label\n",
    "#   4. Use SHAP to explain WHY the model made that prediction\n",
    "#   5. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dc430",
   "metadata": {},
   "source": [
    "### --- Step 1: Helper function for SHAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed10f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: x will come as a numpy array with shape (N, H, W, C).\n",
    "#       Convert it to a torch tensor (N, C, H, W), run through the model,\n",
    "#       return probabilities as numpy.\n",
    "def model_forward(x):\n",
    "    # Ensure batch np.array\n",
    "    if isinstance(x, list):\n",
    "        x = np.stack(x, axis=0)\n",
    "\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    # If images are 0–255, scale to 0–1\n",
    "    if x.max() > 1.0:\n",
    "        x = x / 255.0\n",
    "\n",
    "    # Match training normalization: Normalize(mean=0.5, std=0.5) per channel\n",
    "    x = (x - 0.5) / 0.5  # -> [-1, 1]\n",
    "\n",
    "    # To torch tensor with shape (N, C, H, W)\n",
    "    xt = torch.from_numpy(x).permute(0, 3, 1, 2).to(device)\n",
    "\n",
    "    # Forward pass -> probabilities\n",
    "    with torch.no_grad():\n",
    "        logits = model(xt)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4288bc",
   "metadata": {},
   "source": [
    "### --- Step 2: Pick one test image ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43023adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select an image from test_dataset\n",
    "# HINT: take sample_img, sample_label = test_dataset[0] (or a random index)\n",
    "# TODO: Predict class probabilities using the model\n",
    "# TODO: Print predicted class (with probability) and true label\n",
    "# (use id2label to show class names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ec55a",
   "metadata": {},
   "source": [
    "### --- Step 3: Prepare image for SHAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd982d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the image into numpy format (H, W, C)\n",
    "# HINT: remember test_dataset gives (C, H, W), so you might need np.transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4649d1",
   "metadata": {},
   "source": [
    "### --- Step 4: Create SHAP explainer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a masker for images\n",
    "# HINT: shap.maskers.Image(\"blur(28,28)\", img_np.shape)\n",
    "# TODO: Create an Explainer with (model_forward, masker)\n",
    "# TODO: Run explainer on your selected image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8481e4",
   "metadata": {},
   "source": [
    "### --- Step 5: Visualize ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the original image and the SHAP heatmap side by side\n",
    "# HINT: use matplotlib subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851eb31f",
   "metadata": {},
   "source": [
    "## ========= 7) Extension: Multiple Images ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loop over 5 random test images\n",
    "# For each:\n",
    "#   - Show original image with true label\n",
    "#   - Predict with the model and show predicted label + probability\n",
    "#   - Plot SHAP heatmap for predicted class\n",
    "# HINT: Use matplotlib with 2 rows and 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233f01b",
   "metadata": {},
   "source": [
    "## ========= 8) Reflection ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer in text (Markdown or comments):\n",
    "# 1. Why did the model predict this class?\n",
    "# 2. Are the SHAP heatmaps focusing on meaningful regions?\n",
    "# 3. What differences do you see between correct and incorrect predictions?\n",
    "# 4. How could interpretability help improve this model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "respAI3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
